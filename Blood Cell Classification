# -*- coding: utf-8 -*-
"""BloodCellClassification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cW98ZGFU2nO6oEwki4FKWi_e0dDUNWfD
"""

import tensorflow as tf
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import math
from google.colab import files
from google.colab import drive
drive.mount('/content/drive')
import zipfile
import os
from tensorflow import keras
from PIL import Image
from PIL import ImageOps
from glob import glob

# Commented out IPython magic to ensure Python compatibility.
# %cd "/content/drive/MyDrive/2025-2026/FA25/BME"

zip_file_path = "/content/drive/MyDrive/2025-2026/FA25/BME/blood-cells-image-dataset.zip"
extracted_dir = "/content/drive/MyDrive/2025-2026/FA25/BME/blood-cells"

# Create the extraction directory if it doesn't exist
os.makedirs(extracted_dir, exist_ok=True)

# Extract the zip file
with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
    zip_ref.extractall(extracted_dir)

print(f"Files extracted to: {extracted_dir}")

#Setup file structure
folders = glob(extracted_dir+"/bloodcells_dataset/*")
print(len(folders))

#Number of blodoc cell categories
catagories = len(folders)



def preprocessImage(imagePath,newRes):
  img = Image.open(imagePath)
  img = img.resize(newRes)
  img = np.array(img)
  img = img/255.0
  return img

df = pd.DataFrame()
res = (128,128)
i = 0
for folder in folders:
  print(folder)
  files = glob(folder+"/*.jpg")
  print(len(files))
  for file in files:
    print(file)
    label = np.zeros(catagories)
    label[i] = 1
    img = preprocessImage(file,res)
    new_data =  pd.DataFrame({'img': [img], 'Label': [label]})

    df = pd.concat([df, new_data], ignore_index=True)
  i+=1

df.to_pickle(extracted_dir+'preprocess_dataframe.pkl')

import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.image import ImageDataGenerator

datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.1,
    height_shift_range=0.1,
    zoom_range=0.2,
    shear_range=0.15,
    horizontal_flip=True,
    brightness_range=[0.8, 1.2],
    fill_mode='nearest'
)

## SHOW EXAMPLES OF AUGMENTED IMAGES HERE

train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.1,
    height_shift_range=0.1,
    zoom_range=0.2,
    shear_range=0.15,
    horizontal_flip=True,
    brightness_range=[0.8, 1.2],
    fill_mode='nearest',
    validation_split=0.3 # 70/30 SPLIT HERE

)

train_generator = train_datagen.flow_from_directory(
    '/content/drive/MyDrive/2025-2026/FA25/BME/blood-cells/bloodcells_dataset',
    target_size=(128,128),
    batch_size=16,
    class_mode='categorical',
    subset='training'
)

val_generator = train_datagen.flow_from_directory(
    '/content/drive/MyDrive/2025-2026/FA25/BME/blood-cells/bloodcells_dataset',
    target_size=(128,128),
    batch_size=16,
    class_mode='categorical',
    subset='validation'
)

# SIMPLE CNN

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.optimizers import Adam

model_cnn = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(128,128,3)),
    MaxPooling2D(pool_size=(2,2)),

    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(pool_size=(2,2)),

    Conv2D(128, (3,3), activation='relu'),
    MaxPooling2D(pool_size=(2,2)),

    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.4),
    Dense(train_generator.num_classes, activation='softmax')
])

model_cnn.compile(
    optimizer=Adam(learning_rate=1e-4),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

model_cnn.summary()

simple_cnn = model_cnn.fit(
    train_generator,
    validation_data=val_generator,
    epochs=15,
    verbose=1
)

plt.figure(figsize=(10,4))

plt.subplot(1,2,1)
plt.plot(simple_cnn.history['accuracy'], label='Train Accuracy')
plt.plot(simple_cnn.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

plt.subplot(1,2,2)
plt.plot(simple_cnn.history['loss'], label='Train Loss')
plt.plot(simple_cnn.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.tight_layout()
plt.show()

val_loss, val_acc = model_cnn.evaluate(val_generator)
print(f"Validation Accuracy: {val_acc*100:.2f}%")

model_cnn.save('/content/drive/MyDrive/2025-2026/FA25/BME/custom_cnn_bloodcells.h5')

# INCEPTION NET - restarted runtime here

from tensorflow.keras.applications import InceptionV3
from tensorflow.keras.models import Model
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout
from tensorflow.keras.optimizers import Adam

base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(128,128,3))

for layer in base_model.layers[:200]:
    layer.trainable = False

x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dropout(0.4)(x)
x = Dense(256, activation='relu')(x)
x = Dropout(0.3)(x)
output = Dense(train_generator.num_classes, activation='softmax')(x)

model_inception = Model(inputs=base_model.input, outputs=output)

model_inception.compile(
    optimizer=Adam(learning_rate=1e-4),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

model_inception.summary()

history_inception = model_inception.fit(
    train_generator,
    epochs=15,
    validation_data=val_generator
)

# reduced number of epochs here to avoid runtime crash

# speeds up process while avoiding runtime crash

from tensorflow.keras import mixed_precision
mixed_precision.set_global_policy('mixed_float16')

from tensorflow.keras.applications import InceptionV3
from tensorflow.keras.models import Model
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import backend as K
import gc


# 80/20 split here

train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=25,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.3,
    brightness_range=[0.7, 1.3],
    horizontal_flip=True,
    vertical_flip=True,
    validation_split=0.2
)

train_generator = train_datagen.flow_from_directory(
    '/content/drive/MyDrive/2025-2026/FA25/BME/blood-cells/bloodcells_dataset',
    target_size=(128,128),
    batch_size=16,
    class_mode='categorical',
    subset='training'
)

val_generator = train_datagen.flow_from_directory(
    '/content/drive/MyDrive/2025-2026/FA25/BME/blood-cells/bloodcells_dataset',
    target_size=(128,128),
    batch_size=16,
    class_mode='categorical',
    subset='validation'
)


base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(128,128,3))

# freeze layers for computational optimization
for layer in base_model.layers[:150]:
    layer.trainable = False

x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dropout(0.4)(x)
x = Dense(256, activation='relu')(x)
x = Dropout(0.3)(x)
output = Dense(train_generator.num_classes, activation='softmax')(x)

model_inception = Model(inputs=base_model.input, outputs=output)

model_inception.compile(
    optimizer=Adam(learning_rate=1e-4),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# SAVES MODEL IN CASE CRASH

checkpoint = ModelCheckpoint(
    '/content/drive/MyDrive/2025-2026/FA25/BME/inception_final.h5',
    monitor='val_accuracy',
    save_best_only=True,
    mode='max',
    verbose=1
)

steps_per_epoch = len(train_generator)
validation_steps = len(val_generator)

history_inception = model_inception.fit(
    train_generator,
    steps_per_epoch=steps_per_epoch,
    validation_data=val_generator,
    validation_steps=validation_steps,
    epochs=10,
    callbacks=[checkpoint],
    verbose=1
)

val_loss, val_acc = model_inception.evaluate(val_generator)
print(f"Validation Accuracy: {val_acc*100:.2f}%")

model_inception.save('/content/drive/MyDrive/2025-2026/FA25/BME/inception_highacc_final.h5')

from tensorflow.keras.models import load_model

model_inception = load_model('/content/drive/MyDrive/2025-2026/FA25/BME/inception_final.h5')

from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2
)

val_generator = train_datagen.flow_from_directory(
    '/content/drive/MyDrive/2025-2026/FA25/BME/blood-cells/bloodcells_dataset',
    target_size=(128,128),
    batch_size=16,
    class_mode='categorical',
    subset='validation'
)

val_loss, val_acc = model_inception.evaluate(val_generator)
print(f"Validation Accuracy: {val_acc*100:.2f}%")
print(f"Validation Loss: {val_loss:.4f}")

import matplotlib.pyplot as plt

epochs = [1, 2, 3, 4, 5, 6]
train_acc = [0.556, 0.856, 0.893, 0.916, 0.925, 0.936]
val_acc   = [0.857, 0.883, 0.899, 0.912, 0.920, 0.930]
train_loss = [1.27, 0.423, 0.316, 0.247, 0.219, 0.216]
val_loss   = [0.417, 0.345, 0.282, 0.253, 0.241, 0.220]

plt.figure(figsize=(8,6))
plt.plot(epochs, train_acc, marker='o', label='Training Accuracy')
plt.plot(epochs, val_acc, marker='o', label='Validation Accuracy')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend(); plt.grid(True); plt.show()

plt.figure(figsize=(8,6))
plt.plot(epochs, train_loss, marker='o', label='Training Loss')
plt.plot(epochs, val_loss, marker='o', label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(); plt.grid(True); plt.show()

from sklearn.metrics import classification_report, confusion_matrix
import numpy as np, seaborn as sns

val_generator.reset()
pred = model_inception.predict(val_generator, verbose=1)
y_pred = np.argmax(pred, axis=1)
y_true = val_generator.classes
labels = list(val_generator.class_indices.keys())

print(classification_report(y_true, y_pred, target_names=labels))

cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(8,6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=labels, yticklabels=labels)
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()
